{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddbfc45-6dec-4c73-9034-78688948e4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_10448\\4177561071.py:12: FutureWarning: The argument 'date_parser' is deprecated and will be removed in a future version. Please use 'date_format' instead, or read your data in as 'object' dtype and then call 'to_datetime'.\n",
      "  series = pd.read_csv('C:/Users/DELL/Documents/ASSIMILATION/data.csv', header=0, index_col=0, parse_dates=True, date_parser=analyseur)\n",
      "C:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Définition d'une fonction d'analyseur pour convertir les chaînes de date en objets datetime\n",
    "def analyseur(x):\n",
    "    return pd.to_datetime(x)\n",
    "\n",
    "# Chargement du jeu de données à partir d'un fichier CSV\n",
    "series = pd.read_csv('C:/Users/DELL/Documents/ASSIMILATION/data.csv', header=0, index_col=0, parse_dates=True, date_parser=analyseur)\n",
    "\n",
    "# Suppression des lignes avec des valeurs manquantes (NaN)\n",
    "series = series.dropna()\n",
    "\n",
    "# Conversion de l'index en un Index de périodes avec une fréquence quotidienne\n",
    "series.index = series.index.to_period('D')\n",
    "\n",
    "# Extraction des valeurs de la colonne 'Bel Air' en tant que données de séries temporelles\n",
    "X = series['Bel Air'].values\n",
    "\n",
    "# Calcul de la taille pour l'ensemble d'entraînement (80 % des données)\n",
    "size = int(len(X) * 0.80)\n",
    "\n",
    "# Séparation des données en ensembles d'entraînement et de test\n",
    "train, test = X[0:size], X[size:len(X)]\n",
    "\n",
    "# Initialisation d'un buffer P + 6 pour stocker les valeurs prédites\n",
    "buffer_plus_six = []\n",
    "\n",
    "# Initialisation d'une liste pour stocker les observations correspondantes (P + 6)\n",
    "observed_plus_six = []\n",
    "\n",
    "# Boucle de validation pas à pas\n",
    "for t in range(len(test) - 5):\n",
    "    # Création d'un modèle ARIMA avec un ordre de (3, 0, 2)\n",
    "    model = ARIMA(train, order=(3, 0, 2))\n",
    "    \n",
    "    # Ajustement du modèle aux données historiques\n",
    "    model_fit = model.fit()\n",
    "    \n",
    "    # Prévision des six prochaines valeurs (P + 6)\n",
    "    yhat = model_fit.forecast(steps=7)[1:]  # Prévision des deuxième à septième valeurs (P + 6)\n",
    "    \n",
    "    # Stockage des valeurs prédites\n",
    "    buffer_plus_six.extend(yhat)\n",
    "    \n",
    "    # Stockage des valeurs réelles correspondantes (P + 6)\n",
    "    observed_plus_six.extend(test[t:t+6])\n",
    "    \n",
    "    # Ajout des valeurs réelles aux données d'entraînement pour les prochaines itérations\n",
    "    train = np.append(train, test[t:t+5])\n",
    "\n",
    "# Calcul du coefficient de corrélation entre les valeurs prédites et observées (P + 6)\n",
    "correlation = np.corrcoef(observed_plus_six, buffer_plus_six)[0, 1]\n",
    "print('Coefficient de corrélation (P + 6) : %.3f' % correlation)\n",
    "\n",
    "# Calcul de l'erreur quadratique moyenne (RMSE) entre les valeurs prédites et observées (P + 6)\n",
    "rmse = np.sqrt(mean_squared_error(observed_plus_six, buffer_plus_six))\n",
    "print('RMSE (P + 6) : %.3f' % rmse)\n",
    "\n",
    "# Création d'un DataFrame pour les prédictions P + 6 et les observations correspondantes\n",
    "results_df = pd.DataFrame({'Observé (P + 6)': observed_plus_six, 'Prédit (P + 6)': buffer_plus_six})\n",
    "\n",
    "# Sauvegarde du DataFrame dans un fichier CSV\n",
    "results_df.to_csv('predictions_p_plus_six.csv', index=False)\n",
    "\n",
    "# Tracé des valeurs observées (P + 6) et prédites (P + 6)\n",
    "plt.plot(observed_plus_six, label='Observé (P + 6)')\n",
    "plt.plot(buffer_plus_six, color='red', label='Prédit (P + 6)')\n",
    "plt.legend()\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Valeur')\n",
    "plt.title('Prédictions P + 6 vs Observations P + 6')\n",
    "plt.show()\n",
    "\n",
    "# Affichage d'un message de confirmation\n",
    "print(\"Prédictions P + 6 enregistrées dans 'predictions_p_plus_six.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b624a53-a87f-4423-addc-2fa0eef6c330",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
